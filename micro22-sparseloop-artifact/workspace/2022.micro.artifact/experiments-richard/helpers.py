import os
import subprocess
from pathlib import Path
import shutil
import logging
import yaml
import matplotlib.pyplot as plt
from pathlib import Path
from parse_timeloop_output import parse_timeloop_stats
import numpy as np

def run_accelergy(
    architecture_yaml,
    component_yaml=None,
    sparse_opts=None,
    constraints=None,
    ERT_output_path="ERT.yaml",
    ART_output_path="ART.yaml"
):
    """
    Run Accelergy to generate ERT and ART files.
    
    Returns:
    dict
        A dictionary containing paths to the generated ERT and ART files
    """
    # Create a temporary directory to store outputs
    temp_dir = Path("accelergy_temp")
    if temp_dir.exists():
        shutil.rmtree(temp_dir)
    temp_dir.mkdir()
    
    # Prepare input files list
    input_files = []
    
    # Add architecture file
    if not os.path.exists(architecture_yaml):
        raise FileNotFoundError(f"Architecture YAML file not found: {architecture_yaml}")
    input_files.append(architecture_yaml)
    
    # Add component files
    if isinstance(component_yaml, list):
        for comp_file in component_yaml:
            if not os.path.exists(comp_file):
                raise FileNotFoundError(f"Component YAML file not found: {comp_file}")
            input_files.append(comp_file)
    else:
        if not os.path.exists(component_yaml):
            raise FileNotFoundError(f"Component YAML file not found: {component_yaml}")
        input_files.append(component_yaml)
    
    # Add sparse opts file
    if sparse_opts is not None:
        if not os.path.exists(sparse_opts):
            raise FileNotFoundError(f"Sparse opts file not found: {sparse_opts}")
        input_files.append(sparse_opts)
    
    # Add constraints file
    if constraints is not None:
        if not os.path.exists(constraints):
            raise FileNotFoundError(f"Constraints file not found: {constraints}")
        input_files.append(constraints)
    
    # Build the Accelergy command
    cmd = ["accelergy"]
    
    # Add input files
    cmd.extend(input_files)
    
    # Specify output directory
    cmd.extend(["-o", str(temp_dir)])
        
    # Run Accelergy
    try:
        print(f"Running Accelergy command: {' '.join(cmd)}")
        result = subprocess.call(cmd)
        
    except subprocess.CalledProcessError as e:
        print(f"Accelergy failed with error code {e.returncode}")
        print(e.stderr)
        raise RuntimeError("Accelergy execution failed")
    
    # Find the generated ERT and ART files
    ert_file = temp_dir / "ERT.yaml"
    art_file = temp_dir / "ART.yaml"
    
    if not ert_file.exists():
        raise FileNotFoundError("ERT file was not generated by Accelergy")
    
    if not art_file.exists():
        raise FileNotFoundError("ART file was not generated by Accelergy")
    
    # Copy the files to the desired output paths
    shutil.copy(ert_file, ERT_output_path)
    shutil.copy(art_file, ART_output_path)
    
    # Cleanup temporary directory
    shutil.rmtree(temp_dir)
    
    # Return paths to the generated files
    return {
        "ERT": ERT_output_path,
        "ART": ART_output_path
    }


def run_timeloop_mapper(
    architecture_yaml,
    workload,
    sparse_opts,
    ERT="ERT.yaml",
    ART="ART.yaml",
    output_mapping_path="searched_mapping.yaml",
    mapper=None,
    config=None,
    constraints=None
):
    """
    Run Timeloop mapper to generate a mapping.
    
    Returns:
    --------
    dict
        A dictionary containing paths to output files and best mapping information
    """
    # Create logger
    logger = logging.getLogger("timeloop_mapper")
    logger.setLevel(logging.DEBUG)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    
    # Create output directory if not provided
    out_dir_path = Path("timeloop_temp")
    if out_dir_path.exists():
        shutil.rmtree(out_dir_path)
    out_dir_path.mkdir()
    
    # Build mapper command
    cmd = ["timeloop-mapper"]
    
    # Add main input files
    cmd.extend([
        architecture_yaml,
        workload,
        sparse_opts
    ])
    
    # Add optional input files if provided
    if constraints is not None:
        cmd.append(constraints)
    if mapper is not None:
        cmd.append(mapper)
    cmd.extend(["--ERT", ERT])
    cmd.extend(["--ART", ART])
    if config is not None:
        cmd.extend(["--mapper-config", config])
    
    # Add output directory
    cmd.extend(["-o", str(out_dir_path)])
    print(cmd)

    # Run the mapper
    try:
        result = subprocess.call(cmd)
        
    except subprocess.CalledProcessError as e:
        logger.error(f"Mapper failed with return code {e.returncode}")
        logger.error(f"Stdout: {e.stdout}")
        logger.error(f"Stderr: {e.stderr}")
        
        # Clean up temp directory if we created one
        if is_temp_dir:
            shutil.rmtree(out_dir_path)
            
        raise RuntimeError("Timeloop mapper execution failed")
    
    # Process outputs
    output_files = {}
    
    # Find all output files
    for output_file in out_dir_path.glob("*"):
        output_files[output_file.name] = str(output_file)
    
    # Find and parse the best mapping
    best_mapping = None
    stats_file = out_dir_path / "timeloop-mapper.map+stats.txt"
    mapping_file = out_dir_path / "timeloop-mapper.map.yaml"

    if stats_file.exists():
        with open(stats_file, 'r') as f:
            stats_text = f.read()
        output_files["stats"] = str(stats_file)
        logger.info("Stats file generated")
    else:
        logger.warning("No stats file found")
    
    if mapping_file.exists():
        with open(mapping_file, 'r') as f:
            best_mapping = yaml.safe_load(f)
        logger.info("Best mapping file found")
    else:
        logger.warning("No best mapping file found")
    
    # Copy to output file and clean up temp dir
    shutil.copy(mapping_file, output_mapping_path)
    shutil.rmtree(out_dir_path)
    
    # Extract key metrics if available
    metrics = {}
    energy_file = out_dir_path / "timeloop-mapper.energy_reference.yaml"
    if energy_file.exists():
        with open(energy_file, 'r') as f:
            energy_data = yaml.safe_load(f)
        try:
            metrics["energy"] = energy_data.get("energy", None)
            metrics["edp"] = energy_data.get("edp", None)
            metrics["area"] = energy_data.get("area", None)
            metrics["cycles"] = energy_data.get("cycles", None)
            logger.info(f"Extracted metrics: Energy={metrics.get('energy')}, EDP={metrics.get('edp')}, Area={metrics.get('area')}, Cycles={metrics.get('cycles')}")
        except (AttributeError, KeyError) as e:
            logger.warning(f"Failed to extract metrics from energy file: {e}")
    else:
        logger.warning("No energy reference file found")
    
    # Create the return data structure
    result_data = {
        "best_mapping": output_mapping_path
    }
    
    return result_data



def run_timeloop(
    arch_yaml,
    workload,
    mapping,
    constraints,
    sparse_opts,
    mapper,
    ert_path,
    art_path,
    output_dir="timeloop_output"
):
    """
    Run Timeloop.
    
    Returns:
    --------
    str
        Path to the output directory
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    print(sparse_opts)

    cmd = [
        "timeloop-model",
        str(arch_yaml),
        str(workload),
        str(mapping),
        str(constraints),
        str(sparse_opts),
        # str(mapper),
        "--ERT", str(ert_path),
        "--ART", str(art_path),
        "-o", str(output_dir)
    ]

    print(f"Running Timeloop:\n{' '.join(cmd)}")
    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode != 0:
        print("Timeloop failed!")
        print(result.stderr)
        return None

    print("Timeloop completed successfully.")
    return output_dir


# import re

# def parse_energy_from_timeloop_output(file_path):
#     energy_dict = {}
#     with open(file_path, 'r') as file:
#         lines = file.readlines()

#     for line in lines:
#         # Match lines with format like: "    Energy (DRAM): 1.23 nJ"
#         match = re.search(r'Energy\s*\((.*?)\):\s*([\d.eE+-]+)\s*nJ', line)
#         if match:
#             component = match.group(1).strip()
#             energy = float(match.group(2))
#             energy_dict[component] = energy

#     return energy_dict



# import matplotlib.pyplot as plt

# def plot_energy_breakdown(energy_dict, chart_type='bar'):
#     labels = list(energy_dict.keys())
#     values = list(energy_dict.values())

#     print(labels)
#     print(values)

#     plt.figure(figsize=(8, 6))
#     if chart_type == 'pie':
#         plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=140)
#         plt.title("Energy Breakdown (Pie Chart)")
#         plt.axis('equal')
#     elif chart_type == 'bar':
#         plt.bar(labels, values, color='skyblue')
#         plt.ylabel("Energy (nJ)")
#         plt.title("Energy Breakdown (Bar Chart)")
#         plt.xticks(rotation=45, ha='right')
#         plt.tight_layout()
#     else:
#         raise ValueError("Unsupported chart type. Use 'pie' or 'bar'.")

#     plt.show()


def plot_read_write_energy(energy_breakdown_pJ):
    """
    Plot read and write energy breakdown given dict of energy breakdown.
    """
    levels = list(energy_breakdown_pJ.keys())
    print(type(energy_breakdown_pJ))
    print(energy_breakdown_pJ)

    read_energies = []
    write_energies = []

    ignore = ["BackingStorage"]

    for level in levels:
        stats = energy_breakdown_pJ[level]
        print(level, "\n\n\n")
        print(stats)
        if level in ignore:
            read_energies.append(0)
            write_energies.append(0)
            continue

        # Skip levels with no detailed energy (e.g., MAC)
        if 'actual_reads_per_instance' not in stats:
            read_energies.append(0)
            write_energies.append(0)
            continue

        read_energy = np.nansum(
            stats['actual_reads_per_instance'] * 
            stats['energy_per_access_per_instance'] * 
            stats['instances']
        )

        write_energy = np.nansum(
            (stats['actual_updates_per_instance'] + stats['actual_fills_per_instance']) *
            stats['energy_per_access_per_instance'] *
            stats['instances']
        )

        read_energies.append(read_energy)
        write_energies.append(write_energy)

    x = np.arange(len(levels))
    width = 0.35

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(x - width/2, read_energies, width, label='Read Energy (pJ)', color='skyblue')
    ax.bar(x + width/2, write_energies, width, label='Write Energy (pJ)', color='orange')

    ax.set_ylabel('Energy (pJ)')
    ax.set_title('Read vs Write Energy per Level')
    ax.set_xticks(x)
    ax.set_xticklabels(levels, rotation=45, ha='right')
    ax.legend()
    ax.grid(axis='y', linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.show()




def test_run(workload_path):
    verbose = True
    architecture = "/home/workspace/2022.micro.artifact/experiments-richard/arch.yaml"
    component = "/home/workspace/2022.micro.artifact/experiments-richard/compound_components.yaml"
    ERT_output_path = "ERT.yaml"
    ART_output_path = "ART.yaml"
    workload = "/home/workspace/2022.micro.artifact/experiments-richard/sparsity_testing/" + workload_path
    mapper = "/home/workspace/2022.micro.artifact/experiments-richard/mapper.yaml"
    mapping = "/home/workspace/2022.micro.artifact/experiments-richard/timeloop_temp/timeloop-mapper.map.yaml"
    constraints = "/home/workspace/2022.micro.artifact/experiments-richard/constraints.yaml"
    sparse_opts = "/home/workspace/2022.micro.artifact/experiments-richard/sparse_opts.yaml"
    
    # Run Accelergy with the provided arguments
    # result = run_accelergy(
    #     architecture_yaml=architecture,
    #     component_yaml=component,
    #     sparse_opts=sparse_opts,
    #     constraints=constraints,
    #     ERT_output_path=ERT_output_path,
    #     ART_output_path=ART_output_path
    # )
    
    # print(f"Generated ERT file: {result['ERT']}")
    # print(f"Generated ART file: {result['ART']}")

    # Run Timeloop mapper with the provided arguments
    out_path = workload_path.strip(".yaml")
    os.makedirs(out_path, exist_ok=True)
    result = run_timeloop_mapper(
        architecture_yaml=architecture,
        workload=workload,
        ERT=ERT_output_path,
        ART=ART_output_path,
        output_mapping_path=out_path + "/searched_mapping.yaml",
        mapper=mapper,
        sparse_opts=sparse_opts,
        constraints=constraints
    )

    mapping_path = result["best_mapping"]

    output_path = run_timeloop(
        arch_yaml=architecture,
        sparse_opts=sparse_opts,
        workload=workload,
        mapping=mapping_path,
        constraints=constraints,
        mapper=mapper,
        ert_path=ERT_output_path,
        art_path=ART_output_path,
        output_dir=out_path
    )

    # # Test plotting functions
    output = parse_timeloop_stats(out_path + "/timeloop-model.map+stats.xml")
    plot_read_write_energy(output["energy_breakdown_pJ"])


def plot_stats():
    output = parse_timeloop_stats("timeloop_output_test/timeloop-model.map+stats.xml")
    plot_read_write_energy(output["energy_breakdown_pJ"])


def plot_total_energy_breakdown():
    output = parse_timeloop_stats("timeloop_output_test/timeloop-model.map+stats.xml")
    energy_breakdown = output["energy_breakdown_pJ"]
    levels = list(energy_breakdown.keys())

    energies = []

    for level in levels:
        stats = energy_breakdown[level]
        energies.append(stats["energy"])

    x = np.arange(len(levels))
    width = 0.35

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(x, energies, width, label='Energy (pJ)', color='skyblue')

    ax.set_ylabel('Energy (pJ)')
    ax.set_title('Energy per Level')
    ax.set_xticks(x)
    ax.set_xticklabels(levels, rotation=45, ha='right')
    ax.legend()
    ax.grid(axis='y', linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.show()